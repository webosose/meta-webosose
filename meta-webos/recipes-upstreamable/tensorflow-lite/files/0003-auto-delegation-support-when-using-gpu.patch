From 12aaf6e861d1e67df18f274d77ada460162d0e91 Mon Sep 17 00:00:00 2001
From: "yeseul.joo" <yeseul.joo@lge.com>
Date: Fri, 18 Nov 2022 14:07:06 +0900
Subject: [PATCH] auto delegation support when using gpu

:Release Notes:
add tensorflow lite patch to support auto delegation

:Detailed Notes:
Support Enable Load Balancing policy for auto delegation library.
Models that contain dequantize node can also be partitioned for load
balancing.

:Testing Performed:
Local Build Test

:QA Notes:
N/A

:Issues Addressed:
N/A

Change-Id: I7cf1ba371517232a2bc12a8dceafb18ebad128e1
Reviewed-on: http://gpro.lge.com/c/webos-pro/tensorflow-webos/+/339944
Reviewed-by: Commit Msg Checker <commit_msg@lge.com>
Reviewed-by: Ban Word Checker <ban_word@lge.com>
Reviewed-by: <yeseul.joo@lge.com>
Reviewed-by: <kijoong.lee@lge.com>
Tested-by: <yeseul.joo@lge.com>
Tested-by: <kijoong.lee@lge.com>
---
Upstream-Status: Pending

 .../lite/delegates/gpu/common/model_builder.cc    |  5 ++++-
 .../lite/delegates/gpu/common/model_builder.h     |  3 ++-
 tensorflow/lite/delegates/gpu/delegate.cc         | 15 ++++++++++++++-
 tensorflow/lite/delegates/gpu/delegate.h          |  5 +++++
 tensorflow/lite/delegates/utils.cc                |  8 +++++---
 tensorflow/lite/delegates/utils.h                 |  7 +++++++
 6 files changed, 37 insertions(+), 6 deletions(-)

diff --git a/tensorflow/lite/delegates/gpu/common/model_builder.cc b/tensorflow/lite/delegates/gpu/common/model_builder.cc
index 1f6beafe78a..67f305735a8 100644
--- a/tensorflow/lite/delegates/gpu/common/model_builder.cc
+++ b/tensorflow/lite/delegates/gpu/common/model_builder.cc
@@ -2630,7 +2630,8 @@ std::unique_ptr<TFLiteOperationParser> NewOperationParser(
 // TODO(impjdi): Check ops' parameters.
 TfLiteIntArray* GetOpsToReplace(
     TfLiteContext* context, bool allow_quant_ops, int max_delegated_partitions,
-    const absl::flat_hash_set<TfLiteBuiltinOperator>* excluded_ops) {
+    const absl::flat_hash_set<TfLiteBuiltinOperator>* excluded_ops,
+    int cpu_fallback_percentage) {
   delegates::IsNodeSupportedFn node_supported_fn =
       [=](TfLiteContext* context, TfLiteNode* node,
           TfLiteRegistration* registration,
@@ -2673,6 +2674,8 @@ TfLiteIntArray* GetOpsToReplace(
 
   delegates::FP16GraphPartitionHelper partition_helper(context,
                                                        node_supported_fn);
+  if(cpu_fallback_percentage != 0)
+    partition_helper.SetCpuFallbackPercentage(cpu_fallback_percentage);
   std::set<std::string> unsupported_nodes_info;
   if (partition_helper.Partition(&unsupported_nodes_info) != kTfLiteOk) {
     return TfLiteIntArrayCreate(0);
diff --git a/tensorflow/lite/delegates/gpu/common/model_builder.h b/tensorflow/lite/delegates/gpu/common/model_builder.h
index 7f1c3188044..bb6e824027e 100644
--- a/tensorflow/lite/delegates/gpu/common/model_builder.h
+++ b/tensorflow/lite/delegates/gpu/common/model_builder.h
@@ -40,7 +40,8 @@ namespace gpu {
 TfLiteIntArray* GetOpsToReplace(
     TfLiteContext* context, bool allow_quant_ops = false,
     int max_delegated_partitions = 1,
-    const absl::flat_hash_set<TfLiteBuiltinOperator>* excluded_ops = nullptr);
+    const absl::flat_hash_set<TfLiteBuiltinOperator>* excluded_ops = nullptr,
+    int cpu_fallback_percentage = 0);
 
 // Extracts TFLite delegate execution plan from the input TFLite context and
 // converts it into generic graph format.
diff --git a/tensorflow/lite/delegates/gpu/delegate.cc b/tensorflow/lite/delegates/gpu/delegate.cc
index 9fdb1a88d12..7dbbb11486e 100644
--- a/tensorflow/lite/delegates/gpu/delegate.cc
+++ b/tensorflow/lite/delegates/gpu/delegate.cc
@@ -95,6 +95,11 @@ class Delegate {
     if (options_.max_delegated_partitions <= 0) {
       options_.max_delegated_partitions = 1;
     }
+    if (options_.cpu_fallback_percentage < 0) {
+      options_.cpu_fallback_percentage = 0;
+    } else if (options_.cpu_fallback_percentage > 100) {
+      options_.cpu_fallback_percentage = 100;
+    }
     if (options_.experimental_flags &
             TFLITE_GPU_EXPERIMENTAL_FLAGS_ENABLE_SERIALIZATION &&
         options_.model_token && options_.serialization_dir) {
@@ -116,6 +121,7 @@ class Delegate {
   int MaxDelegatedPartitions() const {
     return options_.max_delegated_partitions;
   }
+  int CPUFallbackPercentage() const { return options_.cpu_fallback_percentage; }
   int num_delegate_kernels() const { return num_delegate_kernels_; }
 
  private:
@@ -567,9 +573,15 @@ TfLiteStatus DelegatePrepare(TfLiteContext* context, TfLiteDelegate* delegate) {
     excluded_ops.insert(kTfLiteBuiltinSplit);
     excluded_ops.insert(kTfLiteBuiltinSplitV);
   }
+  if(gpu_delegate->CPUFallbackPercentage() != 0) {
+    TFLITE_LOG_PROD(TFLITE_LOG_INFO,
+    "GPU Load Balancing : %d percent CPU Fallback",
+    gpu_delegate->CPUFallbackPercentage());
+  }
   TfLiteIntArray* ops_to_replace =
       GetOpsToReplace(context, gpu_delegate->IsQuantOpsAllowed(),
-                      gpu_delegate->MaxDelegatedPartitions(), &excluded_ops);
+                      gpu_delegate->MaxDelegatedPartitions(), &excluded_ops,
+		      gpu_delegate->CPUFallbackPercentage());
   const auto status = context->ReplaceNodeSubsetsWithDelegateKernels(
       context, kRegistration, ops_to_replace, delegate);
   TFLITE_LOG_PROD(TFLITE_LOG_INFO, "Created %d GPU delegate kernels.",
@@ -595,6 +607,7 @@ TfLiteGpuDelegateOptionsV2 TfLiteGpuDelegateOptionsV2Default() {
   options.max_delegated_partitions = 1;
   options.model_token = nullptr;
   options.serialization_dir = nullptr;
+  options.cpu_fallback_percentage = 0;
   return options;
 }
 
diff --git a/tensorflow/lite/delegates/gpu/delegate.h b/tensorflow/lite/delegates/gpu/delegate.h
index 3a1e1811478..3abb0c5ed2f 100644
--- a/tensorflow/lite/delegates/gpu/delegate.h
+++ b/tensorflow/lite/delegates/gpu/delegate.h
@@ -131,6 +131,11 @@ typedef struct {
   // Set to nullptr in TfLiteGpuDelegateOptionsV2Default(), which implies the
   // delegate will not try serialization.
   const char* model_token;
+
+  // A value between 0 and 100, that represents percentage of nodes that are
+  // forced to run on CPU despite it is supported in GPU.
+  // it's set to 0 in TfLiteGpuDelegateOptionsV2Default().
+  int32_t cpu_fallback_percentage;
 } TfLiteGpuDelegateOptionsV2;
 
 // Populates TfLiteGpuDelegateOptionsV2 as follows:
diff --git a/tensorflow/lite/delegates/utils.cc b/tensorflow/lite/delegates/utils.cc
index 2d56981db73..1501a823244 100644
--- a/tensorflow/lite/delegates/utils.cc
+++ b/tensorflow/lite/delegates/utils.cc
@@ -167,7 +167,7 @@ FP16GraphPartitionHelper::GetNodesOfFirstNLargestPartitionsImpl(
   std::vector<int> ops_to_replace;
 
   if (num_supported_nodes() + constant_dequant_nodes_.size() ==
-      num_total_nodes()) {
+      num_total_nodes() && cpu_fallback_percentage() == 0) {
     // Scenario 1: Full Delegation.
     // We delegate all nodes in this case to avoid unnecessary partitions due to
     // FP16 DEQUANT nodes. This is safe to do since no non-delegated op needs
@@ -186,8 +186,10 @@ FP16GraphPartitionHelper::GetNodesOfFirstNLargestPartitionsImpl(
     if (first_n_partitions.empty()) return ops_to_replace;
     for (int i = 0; i < first_n_partitions.size(); ++i) {
       auto nodes = first_n_partitions[i]->nodes_to_replace;
-      ops_to_replace.insert(ops_to_replace.end(), nodes->data,
-                            nodes->data + nodes->size);
+      auto partition_size = nodes->size
+        - nodes->size * cpu_fallback_percentage() / 100;
+      ops_to_replace.insert(ops_to_replace.end(),
+        nodes->data + nodes->size - partition_size, nodes->data + nodes->size);
     }
   }
 
diff --git a/tensorflow/lite/delegates/utils.h b/tensorflow/lite/delegates/utils.h
index 90dd20e34d9..d06bd12489d 100644
--- a/tensorflow/lite/delegates/utils.h
+++ b/tensorflow/lite/delegates/utils.h
@@ -91,9 +91,14 @@ class GraphPartitionHelper {
     return GetNodesOfFirstNLargestPartitionsImpl(n, min_nodes_per_partition);
   }
 
+  void SetCpuFallbackPercentage(int percentage){ cpu_fallback_percentage_ = percentage; }
+
   int num_total_nodes() const { return num_total_nodes_; }
   int num_supported_nodes() const { return num_supported_nodes_; }
   int num_partitions() const { return partitions_.size(); }
+  int cpu_fallback_percentage() const { return cpu_fallback_percentage_; }
+
+  TfLiteIntArray* GetSupportedNodes() const {return supported_nodes_;}
 
  protected:
   virtual bool IsNodeSupported(TfLiteContext* context, TfLiteNode* node,
@@ -136,6 +141,8 @@ class GraphPartitionHelper {
 
   // Contains an array of supported node indices.
   TfLiteIntArray* supported_nodes_ = nullptr;  // owns the memory
+
+  int cpu_fallback_percentage_ = 0;
 };
 
 // Specialized partitioner for graphs that possibly contain fp16 tensors.
